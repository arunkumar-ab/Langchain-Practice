{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d674698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f763f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000026A64D9C880>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000026A66AE2BC0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=\"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\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c504a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# model.invoke([HumanMessage(content=\"Hi my name is Arun and i am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a79dc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Arun, and you are a Chief AI Engineer!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 112, 'total_tokens': 126, 'completion_time': 0.032874439, 'prompt_time': 0.006351967, 'queue_time': 0.045058713, 'total_time': 0.039226406}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'finish_reason': 'stop', 'logprobs': None}, id='run--798537d6-919a-48a1-9d3e-7a68b20e041f-0', usage_metadata={'input_tokens': 112, 'output_tokens': 14, 'total_tokens': 126})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi My name is Arun and i am Chief AI Engineer\"),\n",
    "    AIMessage(content=\"Nice to meet you, Arun! As a Chief AI Engineer, you must be at the forefront of developing and implementing artificial intelligence solutions. What kind of projects are you currently working on, and what's your focus area in AI (e.g., computer vision, natural language processing, robotics, etc.)? I'm here to chat and learn more about your experiences!\"),\n",
    "    HumanMessage(content=\"What is my name and what do i do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat01\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content= \"Hi my name is Arun and i am a AI engineer\")],\n",
    "    config= config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Arun! Nice to meet you. As an AI engineer, you must be working on some fascinating projects. What kind of AI-related work do you do? Are you into machine learning, natural language processing, computer vision, or something else?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d158b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Arun, and you're an AI engineer!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 84, 'total_tokens': 96, 'completion_time': 0.0239517, 'prompt_time': 0.004231641, 'queue_time': 0.045628665, 'total_time': 0.028183341}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'finish_reason': 'stop', 'logprobs': None}, id='run--d691a7a0-0bbe-4277-8845-895ca4c235cb-0', usage_metadata={'input_tokens': 84, 'output_tokens': 12, 'total_tokens': 96})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content= \"What is my name\")],\n",
    "    config= config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your job is to be an AI engineer, Arun!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 157, 'total_tokens': 169, 'completion_time': 0.0239589, 'prompt_time': 0.006396496, 'queue_time': 0.047356892, 'total_time': 0.030355396}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'finish_reason': 'stop', 'logprobs': None}, id='run--3998fea6-b2c4-4f75-88c3-0f2e48ca3797-0', usage_metadata={'input_tokens': 157, 'output_tokens': 12, 'total_tokens': 169})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content= \"I am an AI engineer\")],\n",
    "    config= config\n",
    ")\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content= \"What is my job\")],\n",
    "    config= config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868a1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not aware of any information about your personal identity, including your name. I'm a text-based AI assistant, and I don't have the ability to retain information about individual users. Each time you interact with me, it's a new conversation. If you'd like to share your name with me, I'd be happy to address you by it!\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now change the session id and try\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config= config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80aece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
